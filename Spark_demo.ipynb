{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 1: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id,SepalLengthCm,SepalWidthCm,PetalLengthCm,PetalWidthCm,Species\r\n",
      "1,5.1,3.5,1.4,0.2,Iris-setosa\r\n",
      "2,4.9,3.0,1.4,0.2,Iris-setosa\r\n",
      "3,4.7,3.2,1.3,0.2,Iris-setosa\r\n",
      "4,4.6,3.1,1.5,0.2,Iris-setosa\r\n"
     ]
    }
   ],
   "source": [
    "! head -5 iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "struct = StructType([\n",
    "        StructField('Id', IntegerType(),True),\n",
    "        StructField('SepalLengthCm', DoubleType(), True),\n",
    "        StructField('SepalWidthCm', DoubleType(), True),\n",
    "        StructField('PetalLengthCm', DoubleType(), True),\n",
    "        StructField('PetalWidthCm', DoubleType(), True),\n",
    "        StructField('Species', StringType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sp = spark.read.csv('iris.csv', header = True, schema = struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.read.csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|summary|                Id|     SepalLengthCm|       SepalWidthCm|     PetalLengthCm|      PetalWidthCm|       Species|\n",
      "+-------+------------------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|  count|               150|               150|                150|               150|               150|           150|\n",
      "|   mean|              75.5| 5.843333333333335| 3.0540000000000007|3.7586666666666693|1.1986666666666672|          null|\n",
      "| stddev|43.445367992456916|0.8280661279778637|0.43359431136217375| 1.764420419952262|0.7631607417008414|          null|\n",
      "|    min|                 1|               4.3|                2.0|               1.0|               0.1|   Iris-setosa|\n",
      "|    max|               150|               7.9|                4.4|               6.9|               2.5|Iris-virginica|\n",
      "+-------+------------------+------------------+-------------------+------------------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sp.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VectorAssembler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+-----------------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|         features|\n",
      "+---+-------------+------------+-------------+------------+-----------+-----------------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|[5.1,3.5,1.4,0.2]|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|[4.6,3.1,1.5,0.2]|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|[5.0,3.6,1.4,0.2]|\n",
      "+---+-------------+------------+-------------+------------+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=['SepalLengthCm', 'SepalWidthCm','PetalLengthCm','PetalWidthCm'], \\\n",
    "                              outputCol = 'features')\n",
    "df_sp = vecAssembler.transform(df_sp)\n",
    "df_sp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|        Species|\n",
      "+---------------+\n",
      "| Iris-virginica|\n",
      "|    Iris-setosa|\n",
      "|Iris-versicolor|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sp.select('Species').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+-----------------+-----+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|         features|label|\n",
      "+---+-------------+------------+-------------+------------+-----------+-----------------+-----+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|[5.1,3.5,1.4,0.2]|  0.0|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|[4.9,3.0,1.4,0.2]|  0.0|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|[4.7,3.2,1.3,0.2]|  0.0|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|[4.6,3.1,1.5,0.2]|  0.0|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|[5.0,3.6,1.4,0.2]|  0.0|\n",
      "+---+-------------+------------+-------------+------------+-----------+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trasform species into number\n",
    "stringIndexer = StringIndexer(inputCol='Species', outputCol='label')\n",
    "df_sp = stringIndexer.fit(df_sp).transform(df_sp)\n",
    "df_sp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_sp.show(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+-----------------+-----+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|         features|label|\n",
      "+---+-------------+------------+-------------+------------+-----------+-----------------+-----+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|[5.1,3.5,1.4,0.2]|  0.0|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|[4.7,3.2,1.3,0.2]|  0.0|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|[4.6,3.1,1.5,0.2]|  0.0|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|[5.0,3.6,1.4,0.2]|  0.0|\n",
      "|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|[5.0,3.4,1.5,0.2]|  0.0|\n",
      "+---+-------------+------------+-------------+------------+-----------+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split into training set and testing set\n",
    "df_train, df_test = df_sp.randomSplit([.75, .25])\n",
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes(featuresCol='features',labelCol='label')\n",
    "model = nb.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NaiveBayes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "|         features|label|       rawPrediction|         probability|prediction|\n",
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "|[4.9,3.0,1.4,0.2]|  0.0|[-11.395821829877...|[0.64130642673914...|       0.0|\n",
      "|[5.4,3.9,1.7,0.4]|  0.0|[-14.045362239663...|[0.66914240728118...|       0.0|\n",
      "|[4.6,3.4,1.4,0.3]|  0.0|[-11.989473142755...|[0.64847840144876...|       0.0|\n",
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_predict = model.transform(df_test.select('features','label'))\n",
    "df_predict.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=DenseVector([4.9, 3.0, 1.4, 0.2]), label=0.0, rawPrediction=DenseVector([-11.3958, -12.439, -12.9709]), probability=DenseVector([0.6413, 0.2259, 0.1327]), prediction=0.0),\n",
       " Row(features=DenseVector([5.4, 3.9, 1.7, 0.4]), label=0.0, rawPrediction=DenseVector([-14.0454, -15.1871, -15.7872]), probability=DenseVector([0.6691, 0.2136, 0.1172]), prediction=0.0),\n",
       " Row(features=DenseVector([4.6, 3.4, 1.4, 0.3]), label=0.0, rawPrediction=DenseVector([-11.9895, -13.0635, -13.5968]), probability=DenseVector([0.6485, 0.2216, 0.13]), prediction=0.0)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(rawPrediction=DenseVector([-11.3958, -12.439, -12.9709])),\n",
       " Row(rawPrediction=DenseVector([-14.0454, -15.1871, -15.7872])),\n",
       " Row(rawPrediction=DenseVector([-11.9895, -13.0635, -13.5968]))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict.select('rawPrediction').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9729052360631307"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator()\n",
    "evaluator.evaluate(df_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from pandas.io.data import DataReader\n",
    "from pandas_datareader import data\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_pd = data.DataReader('AMZN','google').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>136.25</td>\n",
       "      <td>136.61</td>\n",
       "      <td>133.14</td>\n",
       "      <td>133.90</td>\n",
       "      <td>7600543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>133.43</td>\n",
       "      <td>135.48</td>\n",
       "      <td>131.81</td>\n",
       "      <td>134.69</td>\n",
       "      <td>8856456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>134.60</td>\n",
       "      <td>134.73</td>\n",
       "      <td>131.65</td>\n",
       "      <td>132.25</td>\n",
       "      <td>7180977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    Open    High     Low   Close   Volume\n",
       "0 2010-01-04  136.25  136.61  133.14  133.90  7600543\n",
       "1 2010-01-05  133.43  135.48  131.81  134.69  8856456\n",
       "2 2010-01-06  134.60  134.73  131.65  132.25  7180977"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>793.66</td>\n",
       "      <td>799.50</td>\n",
       "      <td>789.51</td>\n",
       "      <td>799.02</td>\n",
       "      <td>2992791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>800.31</td>\n",
       "      <td>814.13</td>\n",
       "      <td>799.50</td>\n",
       "      <td>813.64</td>\n",
       "      <td>4873922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>2017-01-13</td>\n",
       "      <td>814.32</td>\n",
       "      <td>821.65</td>\n",
       "      <td>811.40</td>\n",
       "      <td>817.14</td>\n",
       "      <td>3791945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Open    High     Low   Close   Volume\n",
       "1767 2017-01-11  793.66  799.50  789.51  799.02  2992791\n",
       "1768 2017-01-12  800.31  814.13  799.50  813.64  4873922\n",
       "1769 2017-01-13  814.32  821.65  811.40  817.14  3791945"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sp = spark.createDataFrame(df_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------+------+------+-------+\n",
      "|               Date|  Open|  High|   Low| Close| Volume|\n",
      "+-------------------+------+------+------+------+-------+\n",
      "|1262563200000000000|136.25|136.61|133.14| 133.9|7600543|\n",
      "|1262649600000000000|133.43|135.48|131.81|134.69|8856456|\n",
      "|1262736000000000000| 134.6|134.73|131.65|132.25|7180977|\n",
      "+-------------------+------+------+------+------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sp.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# covert datatype\n",
    "df_sp1 = df_sp.withColumn('data_time',df_sp.Date.cast('timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------+------+------+-------+--------------------+\n",
      "|               Date|  Open|  High|   Low| Close| Volume|           data_time|\n",
      "+-------------------+------+------+------+------+-------+--------------------+\n",
      "|1262563200000000000|136.25|136.61|133.14| 133.9|7600543|180282-09-13 05:1...|\n",
      "|1262649600000000000|133.43|135.48|131.81|134.69|8856456|219406-10-20 22:0...|\n",
      "|1262736000000000000| 134.6|134.73|131.65|132.25|7180977|34543-07-25 05:54...|\n",
      "+-------------------+------+------+------+------+-------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sp1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sp.Date.cast?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Date', 'bigint'),\n",
       " ('Open', 'double'),\n",
       " ('High', 'double'),\n",
       " ('Low', 'double'),\n",
       " ('Close', 'double'),\n",
       " ('Volume', 'bigint'),\n",
       " ('data_time', 'timestamp')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sp1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert date in pandas first\n",
    "df_pd.Date = df_pd.Date.apply(lambda x: time.mktime(x.timetuple()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+------+------+------+-------+----------+\n",
      "|       Date|  Open|  High|   Low| Close| Volume| date_time|\n",
      "+-----------+------+------+------+------+-------+----------+\n",
      "| 1.262592E9|136.25|136.61|133.14| 133.9|7600543|2010-01-04|\n",
      "|1.2626784E9|133.43|135.48|131.81|134.69|8856456|2010-01-05|\n",
      "|1.2627648E9| 134.6|134.73|131.65|132.25|7180977|2010-01-06|\n",
      "+-----------+------+------+------+------+-------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sp = spark.createDataFrame(df_pd)\n",
    "df_sp = df_sp.withColumn('date_time', df_sp.Date.cast('timestamp').cast('date'))\n",
    "df_sp.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?df_pd.Date.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?time.mktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+------+------+------+-------+----------+-----+\n",
      "|       Date|  Open|  High|   Low| Close| Volume| date_time|label|\n",
      "+-----------+------+------+------+------+-------+----------+-----+\n",
      "| 1.262592E9|136.25|136.61|133.14| 133.9|7600543|2010-01-04|    0|\n",
      "|1.2626784E9|133.43|135.48|131.81|134.69|8856456|2010-01-05|    1|\n",
      "|1.2627648E9| 134.6|134.73|131.65|132.25|7180977|2010-01-06|    0|\n",
      "+-----------+------+------+------+------+-------+----------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create lable colum\n",
    "def is_bull(close_price, open_price):\n",
    "    if (close_price - open_price) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "price_change = udf(is_bull, ByteType())\n",
    "df_sp = df_sp.withColumn('label', price_change(df_sp.Close, df_sp.Open))\n",
    "df_sp.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create new features:\n",
    "# 1) last day's price range (High - Low)\n",
    "# 2) last day's volume (scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+------+------+------+-------+----------+-----+------------------+\n",
      "|       Date|  Open|  High|   Low| Close| Volume| date_time|label|       price_range|\n",
      "+-----------+------+------+------+------+-------+----------+-----+------------------+\n",
      "| 1.262592E9|136.25|136.61|133.14| 133.9|7600543|2010-01-04|    0|3.4700000000000273|\n",
      "|1.2626784E9|133.43|135.48|131.81|134.69|8856456|2010-01-05|    1|3.6699999999999875|\n",
      "|1.2627648E9| 134.6|134.73|131.65|132.25|7180977|2010-01-06|    0| 3.079999999999984|\n",
      "+-----------+------+------+------+------+-------+----------+-----+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) price range\n",
    "df_sp1 = df_sp.withColumn('price_range', df_sp.High - df_sp.Low)\n",
    "df_sp1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|       price_range|\n",
      "+------------------+\n",
      "|3.4700000000000273|\n",
      "|3.6699999999999875|\n",
      "| 3.079999999999984|\n",
      "+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sp1.select('price_range').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2) scale volume\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "| Volume|volume_vector|\n",
      "+-------+-------------+\n",
      "|7600543|  [7600543.0]|\n",
      "|8856456|  [8856456.0]|\n",
      "|7180977|  [7180977.0]|\n",
      "+-------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transfer_to_vector = udf(lambda x: Vectors.dense(x), VectorUDT())\n",
    "df_sp2 = df_sp1.withColumn('volume_vector', transfer_to_vector(df_sp1.Volume))\n",
    "df_sp2.select('Volume','volume_vector').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StandardScaler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+------+------+------+-------+----------+-----+------------------+-------------+--------------------+\n",
      "|       Date|  Open|  High|   Low| Close| Volume| date_time|label|       price_range|volume_vector|       volume_scaled|\n",
      "+-----------+------+------+------+------+-------+----------+-----+------------------+-------------+--------------------+\n",
      "| 1.262592E9|136.25|136.61|133.14| 133.9|7600543|2010-01-04|    0|3.4700000000000273|  [7600543.0]|[0.9717404687204194]|\n",
      "|1.2626784E9|133.43|135.48|131.81|134.69|8856456|2010-01-05|    1|3.6699999999999875|  [8856456.0]|[1.3787982646085433]|\n",
      "|1.2627648E9| 134.6|134.73|131.65|132.25|7180977|2010-01-06|    0| 3.079999999999984|  [7180977.0]|[0.8357536518074672]|\n",
      "+-----------+------+------+------+------+-------+----------+-----+------------------+-------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "standardScaler = StandardScaler(withMean=True, inputCol='volume_vector',outputCol='volume_scaled')\n",
    "df_sp2 = standardScaler.fit(df_sp2).transform(df_sp2)\n",
    "df_sp2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------------------+-----+\n",
      "| date_time|       volume_scaled|       price_range|label|\n",
      "+----------+--------------------+------------------+-----+\n",
      "|2010-01-04|[0.9717404687204194]|3.4700000000000273|    0|\n",
      "|2010-01-05|[1.3787982646085433]|3.6699999999999875|    1|\n",
      "|2010-01-06|[0.8357536518074672]| 3.079999999999984|    0|\n",
      "+----------+--------------------+------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sp2.select('date_time','volume_scaled','price_range','label').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+------+------+------+-------+----------+-----+------------------+-------------+--------------------+--------------------+\n",
      "|       Date|  Open|  High|   Low| Close| Volume| date_time|label|       price_range|volume_vector|       volume_scaled|            features|\n",
      "+-----------+------+------+------+------+-------+----------+-----+------------------+-------------+--------------------+--------------------+\n",
      "| 1.262592E9|136.25|136.61|133.14| 133.9|7600543|2010-01-04|    0|3.4700000000000273|  [7600543.0]|[0.9717404687204194]|[0.97174046872041...|\n",
      "|1.2626784E9|133.43|135.48|131.81|134.69|8856456|2010-01-05|    1|3.6699999999999875|  [8856456.0]|[1.3787982646085433]|[1.37879826460854...|\n",
      "|1.2627648E9| 134.6|134.73|131.65|132.25|7180977|2010-01-06|    0| 3.079999999999984|  [7180977.0]|[0.8357536518074672]|[0.83575365180746...|\n",
      "+-----------+------+------+------+------+-------+----------+-----+------------------+-------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=['volume_scaled','price_range'],outputCol='features')\n",
    "df_sp2 = vecAssembler.transform(df_sp2)\n",
    "df_sp2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[0.97174046872041...|    0|\n",
      "|[1.37879826460854...|    1|\n",
      "|[0.83575365180746...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sp2.select('features','label').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_test = df_sp2.randomSplit([.7, .3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "model = lr.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+--------------------+--------------------+----------+\n",
      "| date_time|label|            features|       rawPrediction|         probability|prediction|\n",
      "+----------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|2010-01-04|    0|[0.97174046872041...|[-0.1528829540082...|[0.46185353297942...|       1.0|\n",
      "|2010-01-05|    1|[1.37879826460854...|[-0.1885715199592...|[0.45299632203571...|       1.0|\n",
      "|2010-01-06|    0|[0.83575365180746...|[-0.1453093883969...|[0.46373643866626...|       1.0|\n",
      "+----------+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_predict = model.transform(df_test.select('date_time','label','features'))\n",
    "df_predict.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator()\n",
    "eva"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
